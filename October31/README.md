**Reading Response**
===================
*Material: Eight Lessons Learned about Non-verbal Interactions through Robot Theater by Heather Knight*


I completely agree with the quote from the Pixar animator that robot behaviors can be readable "such that people can figure out what the robot is doing, reasonably predict what the robot will do next, and ultimately interact with the robot in an effective way”. Our in-class discussion last week also looked into how non-verbal interaction - the hyper-realistic facial expression - plays a central role in establishing social meaning. We human beings have long been continuously giving and receiving wordless signals. "There’s an effect associated with every functioning of the body, from moving our foot to taking a step to move our lips to make words." We've developed to learn both known and novel robot gestural and bodily expressions. I was fascinated with non-verbal conveyance in robot performance and would love to experiment with it in our final performance. In my previous experience with animation and performance, I always relied on voiceover as a straightforward solution to convey messages to the audience. I am very interested in how we can have the observers reliably infer our messages from the programmed robots' behaviors. 

Questions:

1. If people often interpret non-verbal robot behaviors by remapping them onto themselves, how do we make sure in our performance that we incorporate a design that most of the audience can relate to while reflecting on their different experience?
